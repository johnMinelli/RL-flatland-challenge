\documentclass[a4paper,14pt]{extreport}
\usepackage[T1]{fontenc}
\usepackage[table]{xcolor}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{hyperref}
%\usepackage{amsthm}
\usepackage{mathtools}
%\usepackage{fancyvrb}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[english]{babel}
%\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{neuralnetwork}
\usepackage{quoting}
\usepackage{changepage}
\usepackage{hyperref}
\usepackage{multirow}

\begin{document}

% First page
\title{
	{{\large{\textsc{Alma Mater Studiorum $\cdot$ University of Bologna}}}}
	\rule{\textwidth}{0.4pt}\vspace{3mm}
	\textbf{Flatland Challenge}
	
	Deep learning course final project
}

\author{Lorenzo borelli (\href{mailto:lorenzo.borelli@studio.unibo.it}{lorenzo.borelli@studio.unibo.it}) 
\\ Giovanni Minelli (\href{mailto:giovanni.minelli2@studio.unibo.it}{giovanni.minelli2@studio.unibo.it}) 
\\ Lorenzo Turrini(\href{mailto:lorenzo.turrini4@studio.unibo.it}{lorenzo.turrini4@studio.unibo.it})}
\date{\today}
\maketitle
\newpage
\tableofcontents
\listoffigures
\listoftables
\newpage

\chapter{Introduction}
\input{chapters/intro}

\chapter{The environment}
\input{chapters/environment}

\chapter{Our environment}
\input{chapters/ourEnvironment}

\chapter{Reinforcement learning}
\input{chapters/rl}

\chapter{Observation}
\input{chapters/observation}

\chapter{Normalization}
\label{chap:normalization}
\input{chapters/normalization}

\chapter{Conclusions and future works}
\input{chapters/conclusions}



\begin{thebibliography}{9}

	
	\bibitem{dqn} 
	Mnih et Al.
	\textit{Playing Atari with Deep Reinforcement learning}. 
	In: (2013). cite arxiv:1312.5602 
	NIPS Deep Learning Workshop 2013. url: \url{http://arxiv.org/abs/
	1312.5602}.
	
	\bibitem{huber} 
	Mnih et Al.
	\textit{Human Level Control Through Deep Reinforcement Learning}. 
	Nature, 518, pages 529–533, 2015.

	\bibitem{kaiming} 
	He et Al.
	\textit{Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}. 
	 ICCV '15: Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), 2015.
	 pp. 1026–1034 \url{https://doi.org/10.1109/ICCV.2015.123}
	 
	 \bibitem{dueling}
	 Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando
	 \textit{Dueling Network Architectures for Deep Reinforcement Learning}
	 Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48.
	 ICML’16.New York, NY, USA: JMLR.org, 2016, pp. 1995–2003.
	 
	 \bibitem{priority}
	 T. Schaul, J. Quan, I. Antonoglou, and D. Silver
	 \textit{Prioritized Experience Replay}
	 In: (2016) cite arxiv:1511.05952
	 Comment: Published at ICLR 2016.
	 
	 \bibitem{gcn}
	 Thomas N. Kipf, Max Welling
	 \textit{Semi-Supervised Classification with Graph Convolutional Networks}
	 ICLR 2017. cite arXiv:1609.02907

	\bibitem{spectralNorma}
	Gogianu, Florin, Tudor Berariu, Mihaela Rosca, Claudia Clopath, Lucian Busoniu, and Razvan Pascanu. \textit{"Spectral Normalisation for Deep Reinforcement Learning: An Optimisation Perspective."} ArXiv.org. 11 May 2021. Web. 21 Sept. 2021.
	
	\bibitem{graphiObserv}
	Stanford2016MULTIAGENTDR,
	Maxim Egorov Stanford,\textit{MULTI-AGENT DEEP REINFORCEMENT LEARNING},2016.
	
	\bibitem{a2c}
	 Nathan Grinsztajn, Olivier Beaumont, Emmanuel Jeannot, Philippe Preux
	 \textit{Geometric deep reinforcement learning for dynamic DAG scheduling}
	 cite arXiv:2011.0433v1 [cs.AI]. 9 Nov - 2020
	


\end{thebibliography}

\end{document}